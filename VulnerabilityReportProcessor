import os
import math
import time
import pandas as pd
import numpy as np
import requests
from datetime import datetime, timedelta
from urllib3.exceptions import InsecureRequestWarning
from utilities.logger_master import logger, log_function_entry_exit
from utilities.cisa_kev_process import CisaKeyProcess
# Disable warnings for insecure requests.
requests.packages.urllib3.disable_warnings(category=InsecureRequestWarning)

@log_function_entry_exit(logger)
class VulnerabilityReportProcessor:
    def __init__(self, data:pd.DataFrame=None, data_file_path:str=None,
                 cisa_kev_df:pd.DataFrame=None, cisa_kev_file_path:str=None, download_cisa_kev: bool = None,
                 severity:int=7, remediation_deadline_age_days:int=180):
        self.data = data if data else self.load_report_data(data_file_path)
        self.severity = severity
        self.quit_execution = False
        self.remediation_deadline_age_days = remediation_deadline_age_days
        self.cisa_kev_df = cisa_kev_df
        self.cisa_kev_file_path = cisa_kev_file_path
        self.download_cisa_kev = download_cisa_kev
        self.today_date_str = datetime.now().strftime("-%Y-%m-%d")
        self.unknown_regions = [['OS'], ['Network'], ['Applications']]
        self.count = []  # Initialize an empty list to store count data
        self.all_workstations = pd.DataFrame()

    def update_is_cisa_kev(self):
        cisa_kev_processor = CisaKeyProcess(
                                data_df=self.data,
                                cisa_kev_df=self.cisa_kev_df,
                                cisa_kev_file_path=self.cisa_kev_file_path,
                                download_cisa_kev=self.download_cisa_kev)
        self.data = cisa_kev_processor.run()
        return self.data

    def filter_to_last_30_days(self):
        # Figure out the date 30 days ago
        target_date = datetime.today() - timedelta(days=30)
        # Conditionally drops rows with a test date greater than 45 days old.
        self.data.drop(self.data[self.data['Vulnerability Test Date'] < target_date].index, inplace=True)
        logger.info('filtered data to exclude recent 30 days data')
        return self.data

    def exclude_false_positive(self):
        # conditions to exclude
        if set(('Vulnerability Title', 'Service Port')).issubset(self.data.columns):
            exclude_condition_1 = (self.data['Vulnerability Title'] == 'X.509 Certificate Subject CN Does Not Match the Entity Name')
            exclude_condition_2 = (self.data['Service Port'].astype('float64').astype('Int64') == 17472)
            self.data = self.data[~(exclude_condition_1 & exclude_condition_2)]
            logger.info('excluded false positives')
        else:
            error_message = f"SKIPPED to exclude false positives - missing columns 'Vulnerability Title', 'Service Port' in data columns: {list(self.data.columns)}"
            logger.info(error_message)
        return self.data

    def filter_to_severity_7(self):
        # DONE: Consider removing hard-coded value for severity.
        # NOTE: Experimenting with a boolean value for sorting the vulnerability. We want v3 scores with a value of 0 to use for v2 score fallback.
        self.data.drop(self.data[self.data['Vulnerability CVSS Score'] < self.severity].index, inplace=True)
        logger.info(f'filtered data by severity score: {self.severity}')
        return self.data

    def update_remediation_deadline(self):
        if 'Vulnerability Age' in self.data.columns:
            self.data['age_temp'] = self.data['Vulnerability Age'].str.replace(' Days', '').str.replace(' Day', '').str.replace(',', '').astype('Int64')
            self.data['Remediation Deadline'] = self.data['age_temp'] - self.remediation_deadline_age_days
            self.data['Remediation Deadline'] = self.data['Remediation Deadline'].astype(str) + ' Days'

            self.data = self.data.drop(columns=['age_temp'])
        return self.data

    def merge_severity_scores(self):
        # NOTE: Built using this strategy https://stackoverflow.com/questions/55498357/update-pandas-column-with-another-columns-values-using-loc
        self.data['Vulnerability CVSS Score'] = np.where(self.data['Vulnerability CVSSv3 Score'].ne(0),
                                                    self.data['Vulnerability CVSSv3 Score'],
                                                    self.data['Vulnerability CVSS Score'])
        # After the above step, delete the v3 row as it is no longer needed.
        self.data.drop('Vulnerability CVSSv3 Score', axis=1, inplace=True)
        return self.data

    def load_report_data(self, target_filename):

        logger.info(f"load report data")
        self.data = pd.read_csv(target_filename, dtype={
            'Asset IP Address': 'str',
            'Asset Names': 'str',
            'Asset Location': 'str',
            'Vulnerability Title': 'str',
            'Vulnerability CVE IDs': 'str',
            'Vulnerability CVSSv3 Score': np.float64,
            'Vulnerability CVSSv2 Score': np.float64,
            #'Vulnerability Risk Score': 'str',
            'Vulnerability Description': 'str',
            'Vulnerability Proof': 'str',
            'Vulnerability Solution': 'str',
            'Asset OS Version': 'str',
            'Asset OS Name': 'str',

            'Asset OS Family': 'str',
            'Vulnerability Age': 'str',
            'Vulnerable Since': 'str',
            'Vulnerability Test Date': 'str',
            'Vulnerability ID': 'str'
        }, low_memory=False)
        if self.data is None or len(self.data) ==0:
            logger.error(f"ERROR: No data could be constructed from : {target_filename}")
            raise Exception(f"ERROR: No data could be constructed from : {target_filename}")

        self.data.fillna('', inplace=True)
        if 'Vulnerability Risk Score' in self.data.columns:
            # Convert 'Vulnerability Risk Score' removing commas and converting to float.
            self.data['Vulnerability Risk Score'] = self.data['Vulnerability Risk Score'].replace(',', '', regex=True)
            self.data['Vulnerability Risk Score'] = pd.to_numeric(self.data['Vulnerability Risk Score'], errors='ignore')
        # Convert date fields from string to datetime.

        if 'Vulnerable Since' in self.data.columns:
            self.data['Vulnerable Since'] = pd.to_datetime(self.data['Vulnerable Since'], errors='ignore')
        if 'Vulnerability Test Date' in self.data.columns:
            self.data['Vulnerability Test Date'] = pd.to_datetime(self.data['Vulnerability Test Date'], errors='ignore')
        return self.data

    def add_vulnerability_cvssv3_severity(self):

        #self.update_remediation_deadline() # Commented since dates are corrupted in db
        def score_to_severity(x):
            # In the column immediately after (Column G?)
            # add a string label identifying the vulnerability as a "high" or
            # "critical" severity for easy human readability and metrics sorting.
            if x == 0:
                return "None"
            elif 0.1 <= x <= 3.9:
                return "Low"
            elif 4.0 <= x <= 6.9:
                return "Medium"
            elif 7.0 <= x <= 8.9:
                return "High"
            elif 9.0 <= x <= 10.0:
                return "Critical"
            return ""
        # The above method destroys the v3 column and overwrites the non-zero v3 values into a single "CVSS score" column. With that
        # created, we then assign the Criticality tags.
        self.data.insert(loc=6, column='Vulnerability CVSSv3 Severity',
                         value=self.data['Vulnerability CVSS Score'].apply(score_to_severity))
        return self.data

    def add_unique_vulnerability_id(self):
        # Add a column at the end that represents the unique ID of the vulnerability.
        # In order words, a specific instance of a vulnerability on a specific asset.
        # This is a concatenation of the asset name and the vulnerabilityID
        self.data['Unique Vulnerability ID'] = self.data['Asset Names'] + ' ' + self.data['Vulnerability ID']
        return self.data

    # Takes a dataframe and performs all the typical process steps on it.
    def perform_standard_processing(self):
        # Every single file is filtered for the last 30 days
        self.exclude_false_positive()
        self.filter_to_last_30_days()
        self.merge_severity_scores()
        # New addition: Add a column for severity level (critical, high, etc).
        # Every single filedis filtered to have only CVSSv3 Severity 7 or Higher.
        self.filter_to_severity_7()
        self.add_vulnerability_cvssv3_severity()
        self.update_is_cisa_kev()
        self.add_unique_vulnerability_id()
        self.data.fillna('', inplace=True)  # Remove any empty entries
        return self.data

